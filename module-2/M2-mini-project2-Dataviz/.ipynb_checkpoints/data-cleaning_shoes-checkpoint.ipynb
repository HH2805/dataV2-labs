{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Visualizing Real World Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./shoes_pic.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to practice creating and interpreting different types of visualizations using real world data.\n",
    "\n",
    "We have chosen to study a dataset of 10,000 women's shoes and their product information provided by Kaggle at https://www.kaggle.com/datafiniti/womens-shoes-prices\n",
    "\n",
    "The dataset includes shoe name, brand, price, and more. Each shoe will have an entry for each price found for it so some shoes may have multiple entries.\n",
    "\n",
    "Note that our dataset is a sample of a larger dataset, which is available on a paying basis through Datafiniti's Product Database.\n",
    "\n",
    "The following codebook is available at https://developer.datafiniti.co/docs/product-data-schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "Pandas and numpy will be needed for the analysis of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we imported the data from the .csv file provided and assigned it to a variable named `shoes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "shoes = pd.read_csv('./data/shoes.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Taking the first look at the data.\n",
    "Let's see how the data looks by using pandas methods like `head()`, `info()` and `describe()`. \n",
    "\n",
    "**First, use the `shape` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19045, 47)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check the size of our data, let's use the shape method.\n",
    "shoes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>colors</th>\n",
       "      <th>count</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>prices.sourceURLs</th>\n",
       "      <th>prices.warranty</th>\n",
       "      <th>quantities</th>\n",
       "      <th>reviews</th>\n",
       "      <th>sizes</th>\n",
       "      <th>skus</th>\n",
       "      <th>sourceURLs</th>\n",
       "      <th>upc</th>\n",
       "      <th>websiteIDs</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVpfBXx21cnluZ0-cKxs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoot</td>\n",
       "      <td>Shoes,Clothing,Women's Shoes,All Women's Shoes</td>\n",
       "      <td>Blue,Multicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-11T09:49:00Z</td>\n",
       "      <td>2016-11-11T09:49:00Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2016-11-11T09:49:00Z\"],\"sourceU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10,9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVpfBXx21cnluZ0-cKxs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoot</td>\n",
       "      <td>Shoes,Clothing,Women's Shoes,All Women's Shoes</td>\n",
       "      <td>Blue,Multicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-11T09:49:00Z</td>\n",
       "      <td>2016-11-11T09:49:00Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2016-11-11T09:49:00Z\"],\"sourceU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10,9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVpfBXx21cnluZ0-cKxs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoot</td>\n",
       "      <td>Shoes,Clothing,Women's Shoes,All Women's Shoes</td>\n",
       "      <td>Blue,Multicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-11T09:49:00Z</td>\n",
       "      <td>2016-11-11T09:49:00Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2016-11-11T09:49:00Z\"],\"sourceU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10,9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id asins brand  \\\n",
       "0  AVpfBXx21cnluZ0-cKxs   NaN  Zoot   \n",
       "1  AVpfBXx21cnluZ0-cKxs   NaN  Zoot   \n",
       "2  AVpfBXx21cnluZ0-cKxs   NaN  Zoot   \n",
       "\n",
       "                                       categories           colors  count  \\\n",
       "0  Shoes,Clothing,Women's Shoes,All Women's Shoes  Blue,Multicolor    NaN   \n",
       "1  Shoes,Clothing,Women's Shoes,All Women's Shoes  Blue,Multicolor    NaN   \n",
       "2  Shoes,Clothing,Women's Shoes,All Women's Shoes  Blue,Multicolor    NaN   \n",
       "\n",
       "              dateAdded           dateUpdated  \\\n",
       "0  2016-11-11T09:49:00Z  2016-11-11T09:49:00Z   \n",
       "1  2016-11-11T09:49:00Z  2016-11-11T09:49:00Z   \n",
       "2  2016-11-11T09:49:00Z  2016-11-11T09:49:00Z   \n",
       "\n",
       "                                        descriptions dimension  ...  \\\n",
       "0  [{\"dateSeen\":[\"2016-11-11T09:49:00Z\"],\"sourceU...       NaN  ...   \n",
       "1  [{\"dateSeen\":[\"2016-11-11T09:49:00Z\"],\"sourceU...       NaN  ...   \n",
       "2  [{\"dateSeen\":[\"2016-11-11T09:49:00Z\"],\"sourceU...       NaN  ...   \n",
       "\n",
       "                                   prices.sourceURLs prices.warranty  \\\n",
       "0  https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...             NaN   \n",
       "1  https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...             NaN   \n",
       "2  https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...             NaN   \n",
       "\n",
       "   quantities reviews  sizes skus  \\\n",
       "0         NaN     NaN   10,9  NaN   \n",
       "1         NaN     NaN   10,9  NaN   \n",
       "2         NaN     NaN   10,9  NaN   \n",
       "\n",
       "                                          sourceURLs  upc websiteIDs weight  \n",
       "0  https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...  NaN        NaN    NaN  \n",
       "1  https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...  NaN        NaN    NaN  \n",
       "2  https://www.walmart.com/ip/Zoot-TT-TRAINER-2.0...  NaN        NaN    NaN  \n",
       "\n",
       "[3 rows x 47 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's then have an initial look at the first 5 rows of our dataset for a first look at the features (columns) and at some of the values.\n",
    "shoes.head(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "We can see from the first 5 rows that there seems to be a significant number of missing data.\n",
    "We can also note that prices.amountMin is the same as prices.amountMax\n",
    "\n",
    "Let's start by having a look into this issue to decide if we should drop some columns.\n",
    "\n",
    "We'll use the info method and the isna() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19045 entries, 0 to 19044\n",
      "Data columns (total 47 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   19045 non-null  object \n",
      " 1   asins                2208 non-null   object \n",
      " 2   brand                18412 non-null  object \n",
      " 3   categories           19045 non-null  object \n",
      " 4   colors               11889 non-null  object \n",
      " 5   count                0 non-null      float64\n",
      " 6   dateAdded            19045 non-null  object \n",
      " 7   dateUpdated          19045 non-null  object \n",
      " 8   descriptions         10780 non-null  object \n",
      " 9   dimension            2418 non-null   object \n",
      " 10  ean                  9816 non-null   float64\n",
      " 11  features             14108 non-null  object \n",
      " 12  flavors              0 non-null      float64\n",
      " 13  imageURLs            17840 non-null  object \n",
      " 14  isbn                 0 non-null      float64\n",
      " 15  keys                 19045 non-null  object \n",
      " 16  manufacturer         8656 non-null   object \n",
      " 17  manufacturerNumber   15903 non-null  object \n",
      " 18  merchants            13688 non-null  object \n",
      " 19  name                 19045 non-null  object \n",
      " 20  prices.amountMin     19044 non-null  object \n",
      " 21  prices.amountMax     19045 non-null  object \n",
      " 22  prices.availability  135 non-null    object \n",
      " 23  prices.color         547 non-null    object \n",
      " 24  prices.condition     12228 non-null  object \n",
      " 25  prices.count         7 non-null      object \n",
      " 26  prices.currency      19036 non-null  object \n",
      " 27  prices.dateAdded     19041 non-null  object \n",
      " 28  prices.dateSeen      19041 non-null  object \n",
      " 29  prices.flavor        6 non-null      object \n",
      " 30  prices.isSale        19039 non-null  object \n",
      " 31  prices.merchant      14294 non-null  object \n",
      " 32  prices.offer         6853 non-null   object \n",
      " 33  prices.returnPolicy  752 non-null    object \n",
      " 34  prices.shipping      4563 non-null   object \n",
      " 35  prices.size          508 non-null    object \n",
      " 36  prices.source        4 non-null      object \n",
      " 37  prices.sourceURLs    19034 non-null  object \n",
      " 38  prices.warranty      20 non-null     object \n",
      " 39  quantities           2 non-null      object \n",
      " 40  reviews              1014 non-null   object \n",
      " 41  sizes                8269 non-null   object \n",
      " 42  skus                 7084 non-null   object \n",
      " 43  sourceURLs           19034 non-null  object \n",
      " 44  upc                  10671 non-null  object \n",
      " 45  websiteIDs           1 non-null      float64\n",
      " 46  weight               830 non-null    object \n",
      "dtypes: float64(5), object(42)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "shoes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "As suspected many columns are null cells. Let's look at the percentage of the empty cells in each columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0.000000\n",
       "asins                   88.406406\n",
       "brand                    3.323707\n",
       "categories               0.000000\n",
       "colors                  37.574166\n",
       "count                  100.000000\n",
       "dateAdded                0.000000\n",
       "dateUpdated              0.000000\n",
       "descriptions            43.397217\n",
       "dimension               87.303754\n",
       "ean                     48.458913\n",
       "features                25.922814\n",
       "flavors                100.000000\n",
       "imageURLs                6.327120\n",
       "isbn                   100.000000\n",
       "keys                     0.000000\n",
       "manufacturer            54.549751\n",
       "manufacturerNumber      16.497768\n",
       "merchants               28.128118\n",
       "name                     0.000000\n",
       "prices.amountMin         0.005251\n",
       "prices.amountMax         0.000000\n",
       "prices.availability     99.291153\n",
       "prices.color            97.127855\n",
       "prices.condition        35.794172\n",
       "prices.count            99.963245\n",
       "prices.currency          0.047256\n",
       "prices.dateAdded         0.021003\n",
       "prices.dateSeen          0.021003\n",
       "prices.flavor           99.968496\n",
       "prices.isSale            0.031504\n",
       "prices.merchant         24.946180\n",
       "prices.offer            64.016802\n",
       "prices.returnPolicy     96.051457\n",
       "prices.shipping         76.040956\n",
       "prices.size             97.332633\n",
       "prices.source           99.978997\n",
       "prices.sourceURLs        0.057758\n",
       "prices.warranty         99.894986\n",
       "quantities              99.989499\n",
       "reviews                 94.675768\n",
       "sizes                   56.581780\n",
       "skus                    62.803886\n",
       "sourceURLs               0.057758\n",
       "upc                     43.969546\n",
       "websiteIDs              99.994749\n",
       "weight                  95.641901\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes.isna().sum()*100/len(shoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "Some of the columns are very high (100% empty or mostly empty). They are the following:\n",
    "- asins (88% empty) : The Amazon identifier for this product.\n",
    "- count (100% empty): The number of units included in the product packaging.\n",
    "- dimension (87% empty): The length, width, and height of the item.\n",
    "- flavors (100% empty): A list of flavors available for this product.\n",
    "- isbn (100% empty): The ISBN code for this product.\n",
    "- prices.availability (close to 100% empty): A true or false if this product is available at this price\n",
    "- prices.color (97%): The color associated with this price.\n",
    "- prices.count (close to 100% empty): The number of units being sold at this price.\n",
    "- prices.flavor (close to 100% empty): The flavor associated with this price.\n",
    "- prices.ReturnPolicy (96%): The return policy associated with this price.\n",
    "- prices.shipping (76%): The shipping terms associated with this price.\n",
    "- prices.size (97%): The size associated with this price.\n",
    "- prices.source (close to 100% empty): A list of URLs where this price was seen.\n",
    "- prices.warranty (close to 100% emty): The warranty associated with this price.\n",
    "- quantities (close to 100% empty): How many units of the product are available from a specific buying source at a given time.\n",
    "- reviews (95%): A list of reviews for this product.\n",
    "- websiteIDs (close to 100% empty): A list of identifiers used by the merchant website.\n",
    "- weight (95%): The weight of this product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "Obviously some of the columns are just non relevant. It would appear that all Datafiniti databases follow the same exact schema. So all Datafinity datasets have empty columns which are those where it made no sense to collect any info.\n",
    "\n",
    "Here are the columns that should not even be in our shoe dataset because they are irrelevant to the shoe business: \"flavors\", \"isbn\",  \"prices.availability\", \"prices.flavor\", \"prices.size\".  \n",
    "Let's drop these colums. \n",
    "\n",
    "Other columns have data that is relevant but not interesting or non-important, such as \"asins\", \"count\", \"dimension\", \"prices.color\", \"prices.returnPolicy\", \"prices.shipping\", \"prices.source\", \"prices.warranty\", \"quantities\", \"reviews\", \"websiteIDs\" and \"weight\". \n",
    "Let's drop them as well.\n",
    "\n",
    "Finally it could have been interesting to study the number of units sold at each price (\"prices.count\"), but there is just not enough of information about it, so let's drop the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes.drop([\"flavors\", \"isbn\", \"prices.availability\", \"prices.flavor\", \"prices.size\", \"asins\", \"count\", \"dimension\", \"prices.color\", \"prices.returnPolicy\", \"prices.shipping\", \"prices.source\", \"prices.warranty\", \"quantities\", \"reviews\", \"websiteIDs\", \"weight\",\"prices.count\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19045, 29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0.000000\n",
       "brand                  3.323707\n",
       "categories             0.000000\n",
       "colors                37.574166\n",
       "dateAdded              0.000000\n",
       "dateUpdated            0.000000\n",
       "descriptions          43.397217\n",
       "ean                   48.458913\n",
       "features              25.922814\n",
       "imageURLs              6.327120\n",
       "keys                   0.000000\n",
       "manufacturer          54.549751\n",
       "manufacturerNumber    16.497768\n",
       "merchants             28.128118\n",
       "name                   0.000000\n",
       "prices.amountMin       0.005251\n",
       "prices.amountMax       0.000000\n",
       "prices.condition      35.794172\n",
       "prices.currency        0.047256\n",
       "prices.dateAdded       0.021003\n",
       "prices.dateSeen        0.021003\n",
       "prices.isSale          0.031504\n",
       "prices.merchant       24.946180\n",
       "prices.offer          64.016802\n",
       "prices.sourceURLs      0.057758\n",
       "sizes                 56.581780\n",
       "skus                  62.803886\n",
       "sourceURLs             0.057758\n",
       "upc                   43.969546\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes.isna().sum()*100/len(shoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 419 duplicated rows. This is probably an error, and it is only 2.2% of our data, so let's drop those duplicated rows.\n",
    "shoes.drop_duplicates(inplace=True)\n",
    "# check\n",
    "shoes.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18626, 29)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check if the types of each column is what we expect. If all columns have the right type, we will be able to do all the operations that we want to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     object\n",
       "brand                  object\n",
       "categories             object\n",
       "colors                 object\n",
       "dateAdded              object\n",
       "dateUpdated            object\n",
       "descriptions           object\n",
       "ean                   float64\n",
       "features               object\n",
       "imageURLs              object\n",
       "keys                   object\n",
       "manufacturer           object\n",
       "manufacturerNumber     object\n",
       "merchants              object\n",
       "name                   object\n",
       "prices.amountMin       object\n",
       "prices.amountMax       object\n",
       "prices.condition       object\n",
       "prices.currency        object\n",
       "prices.dateAdded       object\n",
       "prices.dateSeen        object\n",
       "prices.isSale          object\n",
       "prices.merchant        object\n",
       "prices.offer           object\n",
       "prices.sourceURLs      object\n",
       "sizes                  object\n",
       "skus                   object\n",
       "sourceURLs             object\n",
       "upc                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just one column is numerical. Price columns (\"prices.amountMin\" and \"prices.amountMax\") should be numeric. Let's change them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' 1 3/4\" Pf Ankle Strap Sandal\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4f6088b52816>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshoes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prices.amountMin'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5544\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5545\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5546\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5547\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     ) -> \"BlockManager\":\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m     def convert(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    593\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m         \u001b[1;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 995\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' 1 3/4\" Pf Ankle Strap Sandal\"'"
     ]
    }
   ],
   "source": [
    "shoes['prices.amountMin'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as if there is some text-format data in our price columns. By looking at sample rows we canet see any so this must be an error. Let's force our columns to convert to numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     object\n",
       "brand                  object\n",
       "categories             object\n",
       "colors                 object\n",
       "dateAdded              object\n",
       "dateUpdated            object\n",
       "descriptions           object\n",
       "ean                   float64\n",
       "features               object\n",
       "imageURLs              object\n",
       "keys                   object\n",
       "manufacturer           object\n",
       "manufacturerNumber     object\n",
       "merchants              object\n",
       "name                   object\n",
       "prices.amountMin      float64\n",
       "prices.amountMax      float64\n",
       "prices.condition       object\n",
       "prices.currency        object\n",
       "prices.dateAdded       object\n",
       "prices.dateSeen        object\n",
       "prices.isSale          object\n",
       "prices.merchant        object\n",
       "prices.offer           object\n",
       "prices.sourceURLs      object\n",
       "sizes                  object\n",
       "skus                   object\n",
       "sourceURLs             object\n",
       "upc                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "shoes['prices.amountMin'] = pd.to_numeric(shoes['prices.amountMin'], errors='coerce')\n",
    "shoes['prices.amountMax'] = pd.to_numeric(shoes['prices.amountMax'], errors='coerce')\n",
    "#check\n",
    "shoes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. A deeper look: checking the basic statistics.\n",
    "\n",
    "Let's use the `describe` method to see all the descriptive metrics for our variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ean</th>\n",
       "      <th>prices.amountMin</th>\n",
       "      <th>prices.amountMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.816000e+03</td>\n",
       "      <td>18615.000000</td>\n",
       "      <td>18620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.814182e+11</td>\n",
       "      <td>110.163318</td>\n",
       "      <td>111.989324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.538394e+11</td>\n",
       "      <td>1122.775463</td>\n",
       "      <td>1124.094738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.234978e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.472460e+11</td>\n",
       "      <td>24.990000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.171370e+11</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.867372e+11</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.337610e+12</td>\n",
       "      <td>104350.000000</td>\n",
       "      <td>104350.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ean  prices.amountMin  prices.amountMax\n",
       "count  9.816000e+03      18615.000000      18620.000000\n",
       "mean   7.814182e+11        110.163318        111.989324\n",
       "std    8.538394e+11       1122.775463       1124.094738\n",
       "min    1.234978e+06          0.000000          0.000000\n",
       "25%    6.472460e+11         24.990000         25.000000\n",
       "50%    8.171370e+11         45.000000         45.260000\n",
       "75%    8.867372e+11         80.000000         80.000000\n",
       "max    9.337610e+12     104350.000000     104350.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "First we can see that we have prices at zero, which does not make any sense. It must cleaned off our dataset.\n",
    "\n",
    "Also we can see that min and max stats are very close. There is almost no difference between median at min price and median at max price, same for other percentiles, so that is a hint that probably our 2 columns are mostly the same.\n",
    "Which actually make sense since each row is a different pair of shoes sold at some merchant place. Unless collected over a period where sales occured, it makes sense to consider that there is no max or min price, only a selling price.\n",
    "\n",
    "Mean and median are not aligned especially when price is concerned. The mean is much higher than the median, \n",
    "which means that we probably have some ouliers at the expensive end.\n",
    "Apparently our specimens have a similar distribution when it comes to length and width,\n",
    "with similar values for Q1 and Q3. \n",
    "This means that 50% of our diamonds have a height and length of at least 4.7 mm, and less than 6.5 mm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">NDJM : Il faut Ã©galement remarquer les valeurs minimales Ã  0 pour x y z qui sont aberrantes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have probably noticed that the columns x, y and z have a minimum value of 0. This means that there are one or more rows (or observations) in our dataset that are supposedly representing a diamond that has length, width or depth of 0. Considering that we're talking about a physical object, this is impossible!\n",
    "\n",
    "Now let's proceed to check the rows that have a value of 0 in any of the x, y or z columns. By doing this we want to check if the data we are missing can be obtained using the data that we do have.\n",
    "\n",
    "**Check the columns with `x`, `y` and `z` with value 0 in all of them and comment what you see**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diamonds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-13217b2230aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Nombre de lignes comprenant un zÃ©ro, que ce soit dans la col x, y ou z :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiamonds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiamonds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiamonds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiamonds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'carat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdiamonds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiamonds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiamonds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiamonds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'diamonds' is not defined"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "print('Nombre de lignes comprenant un zÃ©ro, que ce soit dans la col x, y ou z :', diamonds[(diamonds.x==0) | (diamonds.y==0) | (diamonds.z==0)].count()['carat'])\n",
    "diamonds[(diamonds.x==0) | (diamonds.y==0) | (diamonds.z==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "print('Nombre de lignes comprenant un zÃ©ro Ã  la fois dans la col x, y ET z :', diamonds[(diamonds.x==0)&(diamonds.y==0)&(diamonds.z==0)].count()['carat'])\n",
    "diamonds[(diamonds.x==0) & (diamonds.y==0) & (diamonds.z==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On constate que sur les 20 lignes oÃ¹ figure une valeur 0 erronnÃ©es, toutes ont au moins cette valeur dans la colonne z ('depth'). \n",
    "# Pour 7 lignes, la valeur de toutes les colonnes est erronnÃ©e.\n",
    "# 12 lignes ont seulement la valeur Z erronÃ©e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have 20 rows that have a value of 0 in some or all the aforementioned columns.\n",
    "Most of them (12) are missing the z value, which we can obtain using the columns depth, x and y. \n",
    "\n",
    "20 rows with issues represent just 0.03% of our data (20 out of 53940) so it wouldn't be a big deal to remove them. Still, lets try to keep all the data we have. \n",
    "\n",
    "For those 12 rows, we will create a function that applies the formula given in the codebook and get the value of z. We will drop the other rows (8), since they are missing all 3 values or 2 of them.\n",
    "\n",
    "**Create a function named `calculate_z` that applies the function in the codebook to one single row you give to the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "def calculate_z (row):\n",
    "    diamonds.loc[row,'z'] = (diamonds.loc[row,'depth'] * (diamonds.loc[row,'x'] + diamonds.loc[row,'y']) / 200).round(2)\n",
    "    return diamonds.loc[row]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">NDJM : Non, tu prends row en input, et tu renvoies la valeur de z, ta fonction n'est pas bonne</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply it just to the rows with incorrect values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = diamonds[(diamonds.z==0) & (diamonds.x !=0) & (diamonds.y !=0)]\n",
    "rowlist = list(rows.index)\n",
    "print('The rows to change are:', rowlist)\n",
    "zlist= [calculate_z(row) for row in rowlist]\n",
    "print(f'The new z rows are as follows: {zlist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">NDJM :Trop compliquÃ©, Ã§a doit etre bcp plus simple</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "print(diamonds[diamonds.z == 0].count()['x'])\n",
    "print(list(diamonds[diamonds.z == 0].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we leave the other 8 values as they are, it would negatively affect our analysis, because these are data that do not make logical sense. Therefore it is better to consider those values as NaN values, since they are probably the result of a mistake or error during process of measuring and storing these values in a dataset.\n",
    "\n",
    "To replace them we can use the pandas .replace() method and np.NaN.\n",
    "\n",
    "**Replace the zero values in the `z` column for a NaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "diamonds.z = diamonds.z.replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "print(diamonds[diamonds.z == 0].count()['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">NDJM : je suis pas fan du round, plutÃ´t utiliser np.isclose</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Checking for outliers\n",
    "Now we are going to revisit the summary table to check for outliers.\n",
    "\n",
    "**Use the `describe` method again and comment on what you see. After that, check if you have any outliers** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "diamonds.describe()\n",
    "# Our comments won't differ from the 1st time as we have only modified 20 lines out of 59940.\n",
    "# Let's just mention that we can see below that we have droped 8 lines.\n",
    "# Mean and median are not aligned especially when price is concerned. The mean is much higher than the median, \n",
    "# which means that we probably have some ouliers at the expensive end.\n",
    "# Apparently our specimens have a similar distribution when it comes to length and width,\n",
    "# with similar values for Q1 and Q3. \n",
    "# This means that 50% of our diamonds have a height and length of at least 4.7 mm, and less than 6.5 mm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diamonds.boxplot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">NDJM : SÃ©lectionne price au prÃ©alable dans ton boxplot</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your comments here\n",
    "# The boxplot method visually confirms that we have outliers in the price column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To manage these outliers, we are going to filter our DataFrame, we're going to take all the values that have a price higher than the 75th percentile.\n",
    "\n",
    "**Look for that quantile and filter the dataframe to clearly see the outliers. What do you think?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "# Number of outliers by column:\n",
    "print(f'The price 75th percentile is at USD {diamonds.price.quantile(0.75)}. The max price is USD {diamonds.price.max()}, hence about {(diamonds.price.max()/diamonds.price.quantile(0.75)).round(1)} times higher.')\n",
    "print()\n",
    "diamonds[diamonds.price > diamonds.price.quantile(0.75)]\n",
    "\n",
    "# Comments:\n",
    "# The number of outliers as defined by the top 25% most expensive diamonds is 13,481."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is really big and the outliers are really far apart from the rest of the values. To see this more clearly we will use a boxplot, which plots the median, 25th and 75th quartile, the maximum and minimum, as well as any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this code\n",
    "fig, ax = plt.subplots(1,2, figsize=(10, 5))\n",
    "sns.boxplot(y=diamonds.y, ax=ax[0])\n",
    "sns.boxplot(y=diamonds.z, ax=ax[1])\n",
    "plt.subplots_adjust(wspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that all the values are within an acceptable range, but we have 2 big outliers in y and 1 in z. Now we know that our max values for y should be around 10 and the values for z should be around 6, so let's filter our dataset to find values higher than 10 in it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "diamonds[diamonds.z>10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found the outlier, let's use the function we defined earlier to correct this value. \n",
    "First, we need to change the value to 0 (because that's how we defined the function before) and then we will apply it.\n",
    "**Apply `calculate_z` for the row with the outlier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code \n",
    "idx = diamonds.loc[diamonds.z>10,'z'].index[0]\n",
    "print('Row index of outlier =',idx)\n",
    "diamonds.loc[idx,'z'] = 0\n",
    "# check:\n",
    "print(diamonds.loc[48410])\n",
    "calculate_z(48410)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we actually corrected the outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check :\n",
    "diamonds.loc[48410]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now let's validate our new `z`. We will check if we obtain the same value of depth using our validate function. If the formula applies, this means could approximate the real value of `z`.\n",
    "\n",
    "**Apply `validate_z` to the row used earlier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "validate_z(48410)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same for `y`. First, let's filter the DataFrame to find the outliers. We said that the maximum values should be around 10, so let's check what are the values above 10.\n",
    "\n",
    "**Check the values greater than 10 in the `y` column** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "dfy = diamonds[diamonds.y > 10]\n",
    "print(dfy)\n",
    "y_rowlist = list(dfy.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the 31.8 in row 49189 is an outlier for the y value. Also, we can see that the 58.9 value for `y` in row 24067 is actually its depth, so it was a mistake when they introduced the data. Let's create a function to fix these outliers.\n",
    "\n",
    "**Create a function named `calculate_y` to calculate `y` using `z` and `x` the same way you did above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "def calculate_y(row):\n",
    "    diamonds.loc[row,'y'] = ((200 * diamonds.loc[row,'z'] / diamonds.loc[row,'depth']) - diamonds.loc[row,'x']).round(2)\n",
    "    return diamonds.loc[row]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">NDJM : MÃªme chose que pour calculate z</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check the rows that had an outlier in `y`, to check that the values were changed.\n",
    "\n",
    "**Check those rows (also validating with your function) and comment what you see**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "print('Updated rows are as follows:')\n",
    "[calculate_y(row) for row in y_rowlist]\n",
    "diamonds.loc[y_rowlist,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments:\n",
    "# We can see that applying our function to all y values above 10 has corrected those values. \n",
    "# In particular the 2 rows that were the most out of line with the others are now more in synch (58.9 --> 19.28 and 31.8 --> 11.42.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have corrected or dropped all of our outliers, lets plot another box plot to double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this code\n",
    "fig, ax = plt.subplots(1,2, figsize=(10, 5))\n",
    "sns.boxplot(y=diamonds.y, ax=ax[0])\n",
    "sns.boxplot(y=diamonds.z, ax=ax[1])\n",
    "plt.subplots_adjust(wspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you think? Are these values more reasonable?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your thoughts here\n",
    "# We can see that our 3 outliers are still outliers, but their value has decreased tremendously.\n",
    "# It is reasonable to assume that the values of these 3 outliers were incorrect, and that we were right to correct them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once you are happy with your cleaning, save the cleaned data and continue to csv. Your new csv should be named ``diamonds_clean``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "shoes.to_csv('shoesclean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
